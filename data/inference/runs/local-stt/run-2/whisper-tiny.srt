1
00:00:00,000 --> 00:00:08,000
Hello and welcome to a audio data set consisting of one single episode of a non-existent podcast.

2
00:00:08,640 --> 00:00:16,000
Or, I may append this to a podcast that I set up recently regarding my

3
00:00:16,640 --> 00:00:26,000
with my thoughts on speech tech and AI in particular. More AI in generative AI, I would say.

4
00:00:26,720 --> 00:00:34,000
But in any event, the purpose of this voice recording is actually to create a lengthy voice

5
00:00:34,000 --> 00:00:39,840
sample for a quick evaluation of back of the envelope evaluation as they might say for

6
00:00:39,840 --> 00:00:44,240
different speech attacks models. And I'm doing this because I thought I had made a great breakthrough

7
00:00:44,240 --> 00:00:50,960
in my journey with speech tech and that was succeeding in the elusive task of fine-tuning whisper.

8
00:00:51,600 --> 00:00:58,800
Whisper is, and I'm going to just talk, I'm trying to mix up, I'm going to try a few different

9
00:00:59,360 --> 00:01:04,000
styles of speaking, I might whisper something at some points as well. And I'll go back to

10
00:01:04,000 --> 00:01:09,600
speaking loud in a different part. So I'm going to send really like a crazy person because I'm also

11
00:01:09,600 --> 00:01:17,520
going to try to speak at different pitches and cadences in order to really try to put

12
00:01:18,399 --> 00:01:23,280
a speech attacks model through its pieces, which is trying to make sense of, is this guy just

13
00:01:24,000 --> 00:01:30,880
ramling on and coherently in one long sentence or are these just actually a series of

14
00:01:32,960 --> 00:01:37,440
step of standalone, standalone, standalone sentences. And how is it going to handle

15
00:01:37,440 --> 00:01:43,280
step alone? That's not a word. What happens when you use speech attacks and you use a fake word.

16
00:01:43,280 --> 00:01:48,640
And then you're like, wait, that's not actually that word doesn't exist. How does AI handle that? And

17
00:01:49,520 --> 00:01:56,160
these and more are all the questions that I'm seeking to answer in this training data. Now,

18
00:01:56,160 --> 00:02:00,960
why was it trying to find you to whisper? And what is whisper, as I said, I'm going to try to

19
00:02:02,160 --> 00:02:08,240
record this at a couple of different levels of technicality for folks who are in the normal

20
00:02:09,120 --> 00:02:14,960
world and not totally stocked down the rabbit hole of AI. What you have to say is a really wonderful

21
00:02:14,960 --> 00:02:22,480
rabbit hole to be, to be done. It's a really interesting area and speech and voice attack is the

22
00:02:22,480 --> 00:02:28,000
aspect of it that I find actually most, I'm not sure I would say the most interesting because there's

23
00:02:28,000 --> 00:02:34,080
just so much that is fascinating in AI. But the most that I find the most personally transformative

24
00:02:34,160 --> 00:02:41,920
in terms of the impact that it's had on my daily work life and productivity and how I sort of work.

25
00:02:41,920 --> 00:02:49,920
And I'm persevering hard with the task of training, yes, a good solution working for Linux.

26
00:02:49,920 --> 00:02:53,760
Would you have anyone actually, does listen to this not just for the training data and for the actual

27
00:02:53,760 --> 00:03:00,960
content? This is this is sparked. I had, besides the fine tune not working. Well, that was the failure.

28
00:03:01,280 --> 00:03:09,920
I used Claude Codes because one thing's these days that there is nothing sort of solving

29
00:03:10,880 --> 00:03:18,960
you know, the reason of life or something at that's flawed and agentic AI can't do, which is not really

30
00:03:18,960 --> 00:03:24,320
the case. It does seem that way sometimes, but it fails a lot as well. And this is one of those

31
00:03:25,200 --> 00:03:29,760
instances where last week I put together an hour of voice training data.

32
00:03:30,399 --> 00:03:37,280
Basically speaking just random things for three minutes and it was actually kind of tedious because

33
00:03:37,280 --> 00:03:43,200
the texts were really weird. Some of them were it was like AI generated. I tried before

34
00:03:43,200 --> 00:03:48,640
to reach Sherlock Holmes for an hour and I just couldn't, I was so bored after 10 minutes that I was

35
00:03:48,640 --> 00:03:56,720
okay knowing just gonna have to find something out to read. So I used a created with AI Studio

36
00:03:56,800 --> 00:04:03,600
vibe code as a synthetic text generator, which actually I thought was probably a better way of

37
00:04:03,600 --> 00:04:09,920
doing it because it would give me more short samples with more varied content. So I was like okay,

38
00:04:09,920 --> 00:04:16,160
give me a voice note like I'm recording an email, give me a short story to read, give me pros

39
00:04:17,440 --> 00:04:22,320
to read. So I came up with all these different things and they added a little timer to it so I

40
00:04:22,320 --> 00:04:29,040
could see how to let us say well as to one hour. And I spent like an hour, one afternoon or probably

41
00:04:29,040 --> 00:04:36,560
two hours by the time you do retakes on whatever because you want to, it gave me a source of truth

42
00:04:37,280 --> 00:04:43,440
which I'm not sure if that's the scientific way to approach this topic of gathering training data,

43
00:04:43,440 --> 00:04:50,159
but I thought made sense. I have a lot of audio data from recording voice notes which I've also

44
00:04:50,160 --> 00:04:56,160
kind of used being experimenting with using for a different purpose. It's slightly different

45
00:04:56,160 --> 00:05:03,680
annotating task types. It's more text classification experiment or well it's more than that actually

46
00:05:03,680 --> 00:05:12,480
I'm working on a voice app so it's a prototype I guess is really more accurate. But you can do that

47
00:05:12,480 --> 00:05:18,960
and you can work backwards. You listen back to a voice note and you painfully go through one of those

48
00:05:19,039 --> 00:05:24,080
transcribing where you start and stop and scrub around in a new fixie areas but it's really

49
00:05:24,080 --> 00:05:29,039
really pouring to do that. So I thought it would be less tedious in the long term if I just

50
00:05:29,599 --> 00:05:35,200
recorded this source of truth. So it gave me these three minutes snippets. I recorded them

51
00:05:35,200 --> 00:05:43,200
it saved an MP3 and a TXT in the same folder and I created an error that data. So I was very hopeful

52
00:05:43,520 --> 00:05:50,960
that I could actually find you in whisper. I want to find you in whisper because when I got

53
00:05:50,960 --> 00:05:59,280
into voice tech last November my wife was in the US and I was alone at home and when crazy

54
00:05:59,280 --> 00:06:05,840
people like me do really wild things like use voice tech technology that was basically when I

55
00:06:05,840 --> 00:06:11,520
started doing it I didn't feel like a crazy person speaking to myself and my expectations weren't

56
00:06:11,599 --> 00:06:18,719
that high. I used speech tech now and again tried to write as like it would be really cool if you

57
00:06:18,719 --> 00:06:24,479
just like speak into your computer and whatever I tried I used that had Linux support was just

58
00:06:25,359 --> 00:06:30,719
it was not good basically and this blew me away from the first go. I mean it wasn't 100%

59
00:06:31,680 --> 00:06:36,240
accurate either the box and it took work but it was good enough that there was a solid foundation

60
00:06:36,240 --> 00:06:42,880
and it kind of passed that pivot point that it's actually worth doing this. There's a point where

61
00:06:42,880 --> 00:06:48,160
it's so like the transcript is you don't have to get 100% accuracy for it to be worth your time

62
00:06:48,880 --> 00:06:52,960
for it's speech tech to be worth while it isn't your productivity but you do need to get above

63
00:06:52,960 --> 00:07:00,480
let's say 85%. If it's 60% or 50% you inevitably say screw it I'll just type it because you

64
00:07:00,480 --> 00:07:06,080
end up missing errors in the transcript and it becomes actually worse you end up in a worse position

65
00:07:06,080 --> 00:07:12,560
than you started with that's been my experience. So I was like oh this is actually really really good

66
00:07:12,560 --> 00:07:19,440
now how did that happen? The answer is ASR whisper being open sourced and the transformer

67
00:07:19,440 --> 00:07:26,160
architecture if you want to go back to the to the underpinnings which really blows my mind and it's

68
00:07:26,240 --> 00:07:37,280
on my list to reto that paper all you need is attention as attentively as can be done with my limited

69
00:07:37,280 --> 00:07:45,040
brain because it's super super high level stuff super advanced stuff I mean but that I think of all the

70
00:07:45,040 --> 00:07:53,680
things that are fascinating about the sudden rise and AI and the dramatic capabilities I find

71
00:07:53,680 --> 00:07:58,880
fascinating a few people are like hang on you've got this thing that can speak to you like a chatbot

72
00:07:58,880 --> 00:08:04,400
and LLM and then you've got image generation okay so first of all those two things

73
00:08:05,360 --> 00:08:12,240
on the surface have nothing in common so like how did that just happen all at the same time and

74
00:08:12,240 --> 00:08:19,200
then when you extend that further you're like Suno right you can sing a song an AI will like come

75
00:08:19,280 --> 00:08:24,880
up with an instrumental and then you've got whisper and you're like wait a second how did all this

76
00:08:24,880 --> 00:08:30,400
stuff like if it's all AI what's like there has to be some commonality otherwise these are

77
00:08:30,400 --> 00:08:37,439
for these are totally different technologies on the surface of it and the transformer architecture

78
00:08:37,439 --> 00:08:43,520
is as far as I know the answer and I can't even say you can't even pretend that I really understand

79
00:08:44,159 --> 00:08:50,160
what the transformer architecture means in depth but I have scandice and as I said once a

80
00:08:50,720 --> 00:08:57,360
printed I'm really kind of think over it's at some point and I'll probably feel bad about myself

81
00:08:57,360 --> 00:09:02,720
I think because when those guys in the in their 20s like that's crazy I think I asked

82
00:09:02,720 --> 00:09:09,199
you to be one who were the who wrote that paper and how old were they when it was published in

83
00:09:09,200 --> 00:09:14,800
arcs of I was expecting like I don't know what do you imagine I personally imagine kind of like

84
00:09:14,800 --> 00:09:20,400
you know you have these breakthroughs during Covid and things like that were like these kind of

85
00:09:20,400 --> 00:09:25,040
really obscure scientists who are like in their 50s and they've just kind of been laboring labs

86
00:09:25,040 --> 00:09:31,120
and we're really in writing and publishing and kind of obscure academic publications and they

87
00:09:31,120 --> 00:09:37,520
finally like hit a bake or when a noble apprise and then their household names so that was kind

88
00:09:37,600 --> 00:09:43,280
of what I had that was the mental image I'd formed of the birth of arcs of like I wasn't

89
00:09:43,280 --> 00:09:48,560
expecting 20 somethings in San Francisco though I thought that was both very very funny very cool

90
00:09:48,560 --> 00:09:55,600
and actually kind of inspiring it's nice to think that people who you know just you might put them

91
00:09:55,600 --> 00:10:02,079
in the kind of milieu or bubble or world that you are in or incredibly in through you know

92
00:10:02,080 --> 00:10:07,680
the series of connections that are coming up with such literally world changing innovations

93
00:10:07,680 --> 00:10:14,000
so that was I thought anyway that that that was cool okay voice training data how are we doing

94
00:10:14,000 --> 00:10:20,080
we're at by 10 minutes and I'm still talking about voice technology so whisper was brilliant and

95
00:10:20,880 --> 00:10:26,000
I was so excited that I was my first instinct was to like guess like oh my gosh I have to

96
00:10:26,000 --> 00:10:31,760
get like a really good microphone for this so I didn't go on a spending spree because I said

97
00:10:31,840 --> 00:10:37,840
I'm gonna have to just wait a month and see if I still use this and it just kind of became

98
00:10:37,840 --> 00:10:44,800
it's become really part of my daily routine like if I'm writing an email I'll record a voice note

99
00:10:44,800 --> 00:10:49,040
and then I've developed and it's nice to see that everyone is like developing the same

100
00:10:49,600 --> 00:10:55,040
things in parallel like that's my kind of a weird thing to say but when I look I kind of came

101
00:10:55,040 --> 00:11:01,200
when I started working on this these prototypes on GitHub which is where I just kind of share

102
00:11:01,200 --> 00:11:09,600
very freely and loosely ideas and you know first iterations on concepts and for one of

103
00:11:09,600 --> 00:11:15,760
a better word I called it like LLM post processing or cleanup or basically a system prompt that

104
00:11:15,760 --> 00:11:22,880
after you get back the raw text from whisper you run it through model and say okay this is crappy

105
00:11:23,600 --> 00:11:31,040
text like add sentence structure and you know fix it up and now when I'm exploring

106
00:11:31,040 --> 00:11:36,480
the different tools that are out there the people of built I see quite a number of projects have

107
00:11:37,280 --> 00:11:42,480
basically you know done the same thing last that we missed construit I'm not saying for a

108
00:11:42,480 --> 00:11:48,480
millisecond that I inspired them I'm sure this has been a thing that's been integrated into tools

109
00:11:48,480 --> 00:11:53,520
for a while but it's it's the kind of thing that when you start using these tools every day

110
00:11:53,520 --> 00:11:59,760
the need for it is almost instantly apparent because text that doesn't have any punctuation or

111
00:11:59,760 --> 00:12:05,360
paragraph spacing takes a long time to you know it takes so long to get it into a presentable email

112
00:12:05,360 --> 00:12:13,280
that again it's it moves speech tech into that before that inflection point we're like that's just

113
00:12:13,280 --> 00:12:19,040
not worth it it's like it's just be quicker to type this so it's it's a big it's a little touch that

114
00:12:19,040 --> 00:12:26,959
actually is a big deal so I was on whisper and I've been using whisper and I kind of early on

115
00:12:26,959 --> 00:12:32,640
find a couple of tools I couldn't find what I was looking for on Linux which is basically just

116
00:12:32,640 --> 00:12:39,120
something that'll run in the background you'll give it an API key and it'll just like transcribe

117
00:12:39,200 --> 00:12:47,120
with like a little key to start and start the dictation and the issues where I discovered

118
00:12:47,120 --> 00:12:52,800
that like most people involved in creating these projects were very much focused on local models

119
00:12:52,800 --> 00:12:58,800
running whisper locally because you can and I tried that a bunch of times and just never got

120
00:12:58,800 --> 00:13:04,160
results that were as good as the cloud and when I began looking at the cost of the speech tech

121
00:13:04,160 --> 00:13:10,160
to API is what I was spending I just thought there is it's actually in my opinion just one of the

122
00:13:10,160 --> 00:13:15,680
better deals in API spending and in cloud like it's just not that expensive for very very good

123
00:13:15,680 --> 00:13:22,240
models that are much more you know you're going to be able to run the full model the latest model

124
00:13:22,240 --> 00:13:29,199
versus whatever you can run on your average GPU unless you want to buy crazy GPU it doesn't really

125
00:13:29,280 --> 00:13:34,000
make sense to me and I've been a lot of things that I know is kind of like a very much

126
00:13:34,000 --> 00:13:39,040
just everything the people just don't want their voice data and their voice leaving their local

127
00:13:39,040 --> 00:13:45,920
environment maybe for regular few reasons as well but I'm not in that I'm neither really care

128
00:13:45,920 --> 00:13:51,680
about people listening to my gross readest consisting of reminding myself that I need to buy more

129
00:13:51,680 --> 00:13:58,320
beer cheetos and hummus which is kind of the three three staples of my diet during periods of

130
00:13:58,320 --> 00:14:04,640
poor nutrition but the kind of stuff that I transcribe it's just not it's not a it's not a

131
00:14:04,640 --> 00:14:12,800
privacy thing that sort of sensitive about and I don't do anything so you know sensitive or

132
00:14:12,800 --> 00:14:17,760
secure that requires air capping so I looked at the pricing and especially the kind of older

133
00:14:17,760 --> 00:14:24,320
model mini some of them were very very affordable and I did it back the I did a calculation once

134
00:14:24,400 --> 00:14:30,800
with chatchewet and I was like okay this is the API price for I can't remember whatever the model

135
00:14:30,800 --> 00:14:37,440
was let's say I just go out at like nonstop which really happens probably I would say an average

136
00:14:37,440 --> 00:14:42,800
I might dictate 30 to 60 minutes per day if I was probably summing up the emails

137
00:14:44,560 --> 00:14:50,800
documents outlines which is a lot but it's still a fairly modest amount and I was like well

138
00:14:50,800 --> 00:14:56,319
some days I do go on like one or two days right being usually when I'm like kind of I'd do the

139
00:14:56,319 --> 00:15:02,800
house and just have something like I've nothing else to do like if I met a hospital we've a newborn

140
00:15:04,079 --> 00:15:09,040
and you're waiting for like eight hours and hours for an appointment and I would probably have

141
00:15:09,040 --> 00:15:15,520
listened to podcasts before becoming a speech fanatic and I'm like oh wait let me just get down let me

142
00:15:15,520 --> 00:15:20,800
just get these ideas out of my head and that's when I'll go on my speech spinches but those

143
00:15:20,800 --> 00:15:25,680
were like once every few months like not frequently but I said okay let's just say if I'm going

144
00:15:25,680 --> 00:15:34,960
to price out cloud STT if I was like dedicated every second of every waking hour to transcribing

145
00:15:34,960 --> 00:15:41,280
for some odd reason I mean it have to like ease and use the toilet like you know there's only so many

146
00:15:41,360 --> 00:15:47,920
hours I'm awake for so like let's just say a maximum of like 40 hour 45 minutes in the hour

147
00:15:47,920 --> 00:15:53,280
then I said all right let's just say 50 who knows you're dictating on the toilet we do it

148
00:15:53,920 --> 00:16:01,040
so you could just do 60 but whatever I did and every day like you're going flat out seven days

149
00:16:01,040 --> 00:16:07,199
a week dictating nonstop it's like what's my monthly API bill gonna be at this price and it came

150
00:16:07,200 --> 00:16:14,160
out to like 70 or 80 bucks and I was like well that would be an extraordinary amount of dictation

151
00:16:14,160 --> 00:16:20,960
and I would hope that there were some compelling reason more worth more than 70 dollars that I

152
00:16:20,960 --> 00:16:25,760
embarked upon their project so given the dots kind of the max point for me I said that's actually

153
00:16:25,760 --> 00:16:32,080
very very affordable now you're gonna if you want to specide the costs and you want to do the post

154
00:16:32,080 --> 00:16:38,640
processing that I really do feel as valuable that's gonna cost them more as well on the last

155
00:16:38,640 --> 00:16:46,320
you're using Gemini which needless to say is a random person sitting in Jerusalem I have no

156
00:16:46,320 --> 00:16:52,000
affiliation nor with Google nor anthropic nor Gemini nor any major tech vendor for that matter

157
00:16:53,760 --> 00:17:00,240
I like Gemini not so much as a everyday model it's kind of underwhelmed in that respect I would say

158
00:17:00,320 --> 00:17:05,839
but for multi-model I think it's got a lot to offer and I think that the transcribing functionality

159
00:17:05,839 --> 00:17:13,520
whereby it can process audio with the system prompt and both give you transcription that's cleaned

160
00:17:13,520 --> 00:17:20,720
up that reduces two steps to one and that for me is a very very big deal and I feel like even Google

161
00:17:20,720 --> 00:17:27,839
hasn't really sort of thought through how useful the downloadability is more kind of use cases

162
00:17:28,319 --> 00:17:34,000
you can achieve with it because I found in the course of this year just an endless list of

163
00:17:34,959 --> 00:17:40,639
really kind of system prompt system prompt stuff that I can say okay I've used the trick

164
00:17:40,639 --> 00:17:46,320
capture context data for AI which is literally I might speak for if I wanted to have a good bank

165
00:17:46,320 --> 00:17:52,560
of context data about who knows my childhood more realistically maybe my career goals

166
00:17:53,520 --> 00:17:59,520
something that would just be like really boring to type out so I'll just like sit in my car

167
00:17:59,520 --> 00:18:06,480
and record it for 10 minutes and that's 10 minutes you get a lot of information in emails which

168
00:18:06,480 --> 00:18:13,200
is short text just there is a whole bunch and all these workflows kind of require a little bit

169
00:18:13,200 --> 00:18:17,919
of treatment afterwards and different treatment my context pipeline is kind of like just to

170
00:18:17,920 --> 00:18:22,320
extract the bare essential so you end up with me talking very loosely about sort of what

171
00:18:22,320 --> 00:18:27,920
I've done in my career where I've worked where my light work and it goes it condenses that down

172
00:18:27,920 --> 00:18:33,920
to very robotic language that is easy to chunk parse and maybe put into a vector database

173
00:18:33,920 --> 00:18:39,760
Daniel has worked in technology Daniel is a has been working in Martin you know stuff like that

174
00:18:39,760 --> 00:18:46,160
that's not how you would speak but I figure it's probably easier to parse for after all robots

175
00:18:46,800 --> 00:18:52,560
so we've almost got to 20 minutes and this is actually a success because I waste 20 minutes of my

176
00:18:53,600 --> 00:19:00,880
of the evening speaking into my headphone and the levels were a shot and it was clipping and I said

177
00:19:00,880 --> 00:19:06,880
I can't read each and evaluation I have to be fair I have to give the models a chance to do their thing

178
00:19:07,600 --> 00:19:11,520
at what am I hoping to achieve in this okay my function was a daughter's mentioned

179
00:19:11,840 --> 00:19:16,879
Deep Gram STT I'm really really hopeful that this prototype will work and it's a build and

180
00:19:16,879 --> 00:19:22,960
public open source so anyone is welcome to use it if I make anything good but that was really exciting

181
00:19:22,960 --> 00:19:30,160
for me last night when after hours of trying my own prototype seeing someone just made something that

182
00:19:30,160 --> 00:19:36,320
works like that you know you're not going to have to build a custom condo environment and image

183
00:19:36,320 --> 00:19:42,399
I have AMD GPU which makes things much more complicated I didn't find it and I was about to

184
00:19:42,399 --> 00:19:48,240
give up and I said all right let me just give deep grams Linux thing a shot and if this doesn't work

185
00:19:48,879 --> 00:19:53,520
I'm just going to go back to trying to vibe code something myself and when I ran the script

186
00:19:54,560 --> 00:20:01,120
I was using cloud code to do the installation process it ran the script and oh my gosh it works just like that

187
00:20:01,760 --> 00:20:08,479
the tricky thing for all those who wants to know all the nitty ditty degree nitty gritty details

188
00:20:09,919 --> 00:20:14,800
was that I don't think it was actually struggling with transcription but pasting

189
00:20:14,800 --> 00:20:20,320
wailant makes life very hard and I think there was something not running in the right time anyway

190
00:20:20,320 --> 00:20:25,120
Deep Gram I looked at how they actually handled that because it worked out of the box one other stuff

191
00:20:25,120 --> 00:20:32,159
didn't and it was quite a clever little mechanism and but more and so it's not the accuracy was brilliant

192
00:20:32,159 --> 00:20:40,639
now what am I doing here this is going to be a 20 minutes audio sample and I'm I think I've done

193
00:20:40,639 --> 00:20:49,120
one or two of these before but I did this with sure snappy voice notes this is kind of long form

194
00:20:49,520 --> 00:20:54,080
it's actually might be a better approximation for what's useful to me than voice mammals like I

195
00:20:54,080 --> 00:20:59,840
need to buy three beaters of moke tomorrow and Peter bread which is probably how like half my voice

196
00:20:59,840 --> 00:21:04,639
note send like if anyone were to I don't know like find my phone they be like this is the most

197
00:21:04,639 --> 00:21:09,760
boring person in the world although actually there are some like kind of journaling thoughts as well

198
00:21:09,760 --> 00:21:14,800
but it's a lot of content like that and the probably for the evaluation the most useful thing is

199
00:21:15,440 --> 00:21:23,280
slightly obscure tech get hub the clean hooking face not so obscure that is not going to have a chance

200
00:21:23,280 --> 00:21:28,879
of knowing it but hopefully sufficiently well known that the models should get us I tried to do a

201
00:21:28,879 --> 00:21:33,919
little bit of speaking really fast and speaking very slowly I would say in general I've spoken

202
00:21:34,560 --> 00:21:40,159
delivered this at a faster pace than I usually would owe into strong coffee if flowing through my bloodstream

203
00:21:41,040 --> 00:21:45,760
and the thing that I'm not going to get into spent work is background noise which in my first

204
00:21:45,760 --> 00:21:52,000
take that I had to get rid of my wife come in with my son and for a good night kiss and that actually

205
00:21:52,000 --> 00:21:58,560
would have been super helpful to get in because it was non-diorized or if we had diorization

206
00:21:59,440 --> 00:22:03,120
a female I could say I want the male voice and that wasn't intended for transcription

207
00:22:04,480 --> 00:22:07,920
and I'm not going to get background noise like people honking their horns which is something

208
00:22:08,080 --> 00:22:13,440
of done to my main data set where I am trying to go back to some of my voice notes

209
00:22:13,440 --> 00:22:19,920
and I take them and run a benchmark but this is going to be just a pure quick test and

210
00:22:21,200 --> 00:22:28,080
someone working on a voice note idea that's my sort of end motivation besides thinking it's

211
00:22:28,080 --> 00:22:33,440
an astudiate standing technology that's coming to viability and really I know the same it's cheesy

212
00:22:33,520 --> 00:22:40,880
can actually have a very transformative effect it's you know voice technology has been life changing

213
00:22:40,880 --> 00:22:48,640
for folks living with disabilities and I think there's something really nice about the fact that

214
00:22:48,640 --> 00:22:54,560
it can also benefit you know folks who are able bodies and like we can all in different ways

215
00:22:57,040 --> 00:23:01,040
make this tech as useful as possible regardless of the exact way that we're using it

216
00:23:02,000 --> 00:23:06,639
and I think there's something very powerful in that and it can be very cool I see

217
00:23:06,639 --> 00:23:10,800
huge potential what excites me about voice tech a lot of things actually

218
00:23:12,080 --> 00:23:16,000
firstly the fact that it's cheap and accurate as I mentioned at the very start of this

219
00:23:17,200 --> 00:23:19,760
and it's getting better and better with stuff like accent handling

220
00:23:20,879 --> 00:23:25,040
I'm not sure my fine tune will actually ever come to fruition in the sense that I'll use it

221
00:23:25,040 --> 00:23:30,800
day to day as I imagine and get likes you per flawless words error rates because I'm just kind of

222
00:23:30,800 --> 00:23:38,399
skeptical about local speech attacks as I mentioned and I think the pace of innovation and

223
00:23:38,399 --> 00:23:42,720
improvement in the models the main reason for fine tuning from what I've seen

224
00:23:44,240 --> 00:23:51,120
have been people who are something that really blows my mind about ASR is the idea that it's inherently

225
00:23:52,320 --> 00:24:00,080
alien fuel or multilingual fanatic based so as folks who use speak very obsturately languages

226
00:24:00,159 --> 00:24:05,520
that there might be a policy of training data or almost none at all and therefore the accuracy

227
00:24:05,520 --> 00:24:11,840
is significantly reduced or folks in very critical environments I know they're you this is

228
00:24:11,840 --> 00:24:18,080
using extensively in medical transcription and dispatcher work as you know the call centers

229
00:24:18,080 --> 00:24:24,000
use send out ambulances etc where accuracy is absolutely paramount and in the case of doctors

230
00:24:24,560 --> 00:24:29,679
radiologists there might be using very specialized vocab all the time so those are kind of the main

231
00:24:29,760 --> 00:24:35,040
two things and I'm not sure that really just for training make it better on a few random

232
00:24:35,040 --> 00:24:41,360
tech words with my slightly I mean I have an accent but like not you know an accent that a few

233
00:24:41,360 --> 00:24:48,240
other million people have ish I'm not sure that my little fine tune is going to actually

234
00:24:49,440 --> 00:24:54,560
like the bump in word error reduction if I ever actually figure out how to do it and get it up to the

235
00:24:55,520 --> 00:25:00,560
by the time I've done that I suspect that the next generation of ASR will just be so good that

236
00:25:00,560 --> 00:25:06,399
it will kind of be no well that would be cool for a doubt but all this uses instead so that's

237
00:25:06,399 --> 00:25:14,480
going to be is for today's episodes of voice training data single long-shaw evaluation

238
00:25:14,480 --> 00:25:20,560
who am I going to compare with supposed to be a benchmark but I'm more interested in seeing whisper

239
00:25:20,639 --> 00:25:27,679
head to head with two things ready one is whisper variants so you've got these projects like faster whisper

240
00:25:29,120 --> 00:25:33,840
distilled whisper it's a bit confusing there's a whole bunch of them and the emerging ASR is

241
00:25:33,840 --> 00:25:38,879
which are also a thing my intention for this is I'm not sure I'm going to have the time in any point

242
00:25:38,879 --> 00:25:45,840
of the foreseeable future to go back to this whole episode and create a proper source true through

243
00:25:45,840 --> 00:25:53,760
a fix everything might do it if I can get one transcriptions as efficiently close to perfection

244
00:25:54,959 --> 00:25:59,840
but what I would actually love to do on hugging face I think would be a great

245
00:25:59,840 --> 00:26:06,240
probably how I might visualize this is having the audio waveform play and then have the transcript

246
00:26:06,240 --> 00:26:14,720
for each model below it and maybe even a like you know two scale and maybe even a local one as

247
00:26:14,720 --> 00:26:22,960
well like local whisper versus open AI API etc and I can then actually listen back to segments

248
00:26:22,960 --> 00:26:28,960
or anyone who wants to can listen back to segments of this recording and see where a particular

249
00:26:28,960 --> 00:26:34,240
model struggled and others didn't as well as the sort of headline finding of which had the best

250
00:26:34,240 --> 00:26:40,240
WER but that would require the source of truth okay that's it I hope this was I don't know

251
00:26:40,320 --> 00:26:45,760
maybe useful for other folks interested in STT you want to see that I always feel think I've just

252
00:26:45,760 --> 00:26:51,120
said something I didn't and do STT I said for those it's in carefully including hopefully the

253
00:26:51,840 --> 00:26:57,840
models themselves this has been myself Daniel Rosal for more jumbled repository is about my

254
00:26:58,240 --> 00:27:04,640
roving interest in AI but particularly agentic mcp and voice tech you can find me on

255
00:27:04,800 --> 00:27:11,920
get up hugging face where else Daniel Rosal.com which is my personal website as well as

256
00:27:12,560 --> 00:27:17,360
this podcast whose name I sadly cannot remember but the next time thanks for listening

