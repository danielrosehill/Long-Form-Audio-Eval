1
00:00:00,000 --> 00:00:08,640
Hello and welcome to a audio dataset consisting of one single episode of a non-existent podcast.

2
00:00:08,640 --> 00:00:19,120
Or, it eh, I may append this to a podcast that I set up recently regarding my with my thoughts on speech

3
00:00:19,120 --> 00:00:28,720
tech and AI in particular. More AI and generative AI I would, I would say. But in any event, the purpose of this

4
00:00:30,080 --> 00:00:37,120
voice recording is actually to create a lengthy voice sample for a quick evaluation, a back of the

5
00:00:37,120 --> 00:00:42,320
envelope evaluation as they might say for different speech to text models. And I'm doing this because I

6
00:00:42,800 --> 00:00:48,560
I thought I'd made a great breakthrough in my journey with speech tech. And that was succeeding in

7
00:00:48,560 --> 00:00:55,120
the elusive task of fine-tuning Whisper. Whisper is, and I'm going to just talk, I'm trying to

8
00:00:55,760 --> 00:01:01,600
mix up, I'm going to try a few different styles of speaking. I might whisper something at some

9
00:01:01,600 --> 00:01:07,760
points as well. And I'll go back to speaking loud in different parts. I'm going to sound really

10
00:01:07,760 --> 00:01:15,200
like a crazy person because I'm also going to try to speak at different pitches and cadences

11
00:01:15,200 --> 00:01:21,600
in order to really try to put a speech to text model through its paces, which is trying to make

12
00:01:21,600 --> 00:01:30,320
sense of "is this guy just rambling on incoherently in one long sentence?" Or "are these just actually

13
00:01:30,320 --> 00:01:38,320
a series of step standalone stepalone standalone sentences?" And how is it going to handle stepalone?! That's not a

14
00:01:38,320 --> 00:01:43,919
word! What happens when you use speech to text and you use a fake word and then you're like, wait,

15
00:01:43,919 --> 00:01:51,520
that's not actually, that word doesn't exist. How does AI handle that? And these and more are all the

16
00:01:52,880 --> 00:01:57,359
questions that I'm seeking to answer in this training data. Now, why did why was I trying to

17
00:01:57,360 --> 00:02:01,040
fine tune whisper? And what is Whisper? As I said, I'm going to try to

18
00:02:02,080 --> 00:02:04,240
record this at a couple of different levels of

19
00:02:04,880 --> 00:02:10,320
technicality - for folks who are in the normal world and not totally

20
00:02:11,360 --> 00:02:16,079
stuck down the rabbit hole of AI. Which I have to say is a really wonderful rabbit hole to be

21
00:02:16,720 --> 00:02:23,440
to be down. It's a really interesting area. And speech and voice tech is the aspect of it that

22
00:02:23,440 --> 00:02:28,880
I find actually most - I'm not sure I would say the most interesting because there's just so much

23
00:02:28,880 --> 00:02:34,560
that is fascinating in AI. But the most that I find the most personally transformative in terms of

24
00:02:34,560 --> 00:02:42,240
the impact that it's had on my daily work life and productivity and how I sort of work. And

25
00:02:42,960 --> 00:02:49,920
I am persevering hard with the task of trying to get a good solution working for Linux.

26
00:02:49,920 --> 00:02:53,440
Which if anyone actually does listen to this not just for the training data and for the

27
00:02:53,440 --> 00:03:00,399
actual content, this has sparked. I had, besides the fine tune not working, well that was

28
00:03:00,399 --> 00:03:07,679
the failure. I used Claude Code. Because one thinks these days that there is nothing

29
00:03:08,560 --> 00:03:16,799
short of solving, you know, the reason of life or something that Claude and

30
00:03:16,800 --> 00:03:22,720
agentic AI can't do. Which is not really the case. It does seem that way sometimes. But it

31
00:03:22,720 --> 00:03:28,080
fails a lot as well. And this is one of those instances where last week I put together an hour

32
00:03:28,080 --> 00:03:33,600
of voice training data: basically speaking just random things for three minutes. And

33
00:03:35,600 --> 00:03:40,160
it was actually kind of tedious because the texts were really weird. Some of them were it was like,

34
00:03:40,160 --> 00:03:45,440
it was AI generated. I tried before to read Sherlock Holmes for an hour and I just couldn't,

35
00:03:45,440 --> 00:03:51,120
I was so bored after 10 minutes that I was like, "okay, no, I'm just gonna have to find something

36
00:03:51,120 --> 00:03:59,920
else to read." So I used I created with AI Studio, vibe coded, a synthetic text generator,

37
00:04:00,800 --> 00:04:05,680
which actually I thought was probably a better way of doing it because it would give me more

38
00:04:05,680 --> 00:04:12,000
short samples with more varied content. So I was like, okay, give me a voice note. Like I'm

39
00:04:12,000 --> 00:04:18,800
recording an email. Give me a short story to read. Give me prose. So I came up with all

40
00:04:18,800 --> 00:04:24,240
these different things and I added a little timer to it so I could see how close I was to one

41
00:04:24,240 --> 00:04:32,480
hour. And I spent like an hour one afternoon or probably two hours by the time you do retakes

42
00:04:32,480 --> 00:04:39,120
and whatever because you want to. It gave me a source of truth which I'm not sure if that's the

43
00:04:39,120 --> 00:04:45,120
scientific way to approach this topic of gathering training data but I thought made sense.

44
00:04:46,560 --> 00:04:50,880
I have a lot of audio data from recording voice notes which I've also kind of used

45
00:04:52,000 --> 00:04:56,720
been experimenting with using for a different purpose. It's slightly different - annotating

46
00:04:57,840 --> 00:05:03,680
task types. It's more text classification experiment. Or well it's more than that actually

47
00:05:03,680 --> 00:05:08,880
I'm working on a voice app. So it's a prototype I guess is really more accurate.

48
00:05:11,280 --> 00:05:15,920
But you can do that and you can work backwards. You listen back to a voice note and you

49
00:05:17,520 --> 00:05:22,400
painfully go through one of those - transcribing where you start and stop and scrub around it and

50
00:05:22,400 --> 00:05:27,680
you fix the errors . But it's really really boring to do that. So I thought it would be less tedious

51
00:05:27,680 --> 00:05:34,240
in the long term if I just recorded the source of truth. So it gave me these three minute snippets.

52
00:05:34,240 --> 00:05:40,480
I recorded them and saved an MP3 and a TXT in the same folder and I created an hour of that data.

53
00:05:41,840 --> 00:05:47,280
So I was very hopeful  - quitely, you know, a little bit hopeful - that I would be able that I could actually fine tune

54
00:05:47,280 --> 00:05:54,720
Whisper. I want to fine tune Whisper because when I got into voice tech last November my wife was in

55
00:05:54,720 --> 00:06:01,920
the US and I was alone at home. And when crazy people like me do really wild things like use voice

56
00:06:01,920 --> 00:06:08,320
to tech technology that was basically when I started doing it. I didn't feel like a crazy person

57
00:06:08,320 --> 00:06:15,760
speaking to myself. And my expectations weren't that high. I used speech tech now and again

58
00:06:16,960 --> 00:06:21,200
tried it out. I was like "it'd be really cool if you could just like speak into your computer." And

59
00:06:21,280 --> 00:06:28,479
whatever I tried out that had Linux support was just - it was not good, basically. And this blew me away

60
00:06:28,479 --> 00:06:34,400
from the first go. I mean it wasn't 100% accurate out of the box. And it took work. But it was good

61
00:06:34,400 --> 00:06:40,320
enough that there was a solid foundation. And it kind of passed that pivot point that it's actually

62
00:06:40,320 --> 00:06:46,320
worth doing this. You know, there's a point where it's. So like the transcript is you don't have to get 100%

63
00:06:46,400 --> 00:06:51,040
accuracy for it to be worth your time for speech to text to be a worthwhile addition to your

64
00:06:51,040 --> 00:06:58,320
productivity. But you do need to get above let's say I don't know 85%. If it's 60% or 50% you inevitably

65
00:06:58,320 --> 00:07:03,920
say "screw it I'll just type it."Because you end up missing errors in the transcript and it becomes

66
00:07:03,920 --> 00:07:07,840
actually worse. You end up in a worse position than you started with it. That's been my experience.

67
00:07:08,400 --> 00:07:14,400
So I was like "oh, this is actually really really good. Now how did that happen?" The answer is

68
00:07:14,400 --> 00:07:21,599
ASR, Whisper being open-sourced. and the transformer architecture if you want to go back to the

69
00:07:23,200 --> 00:07:29,440
to the underpinnings. Which really blows my mind. And it's on my list to read through that paper

70
00:07:30,239 --> 00:07:38,400
'All You Need Is Attention' as attentively as can be done with my limited brain. Because it's super

71
00:07:38,960 --> 00:07:45,679
high-level stuff - super advanced stuff I mean. But that I think of all the things that

72
00:07:47,280 --> 00:07:54,080
are fascinating about the sudden rise and AI and the dramatic capabilities I find it fascinating

73
00:07:54,080 --> 00:07:59,599
that few people are like "hang on, you've got this thing that can speak to you like a chatbot - an LLM.

74
00:08:00,640 --> 00:08:06,799
Then you've got image generation. Okay, so firstly those two things on the surface have nothing

75
00:08:06,800 --> 00:08:12,560
in common. So like, "how are they ... how did THAT just happen all at the same time?" And then when you

76
00:08:12,560 --> 00:08:19,920
extend that further you're like Suno right. You can sing a song and AI will like come up with

77
00:08:19,920 --> 00:08:25,200
an instrumental.  And then you've got Whisper. And then you're like "wait a second how did all this stuff

78
00:08:25,200 --> 00:08:30,880
like if it's all AI what's like, there has to be some commonality. Otherwise these are four these are

79
00:08:31,600 --> 00:08:38,640
totally different technologies on the surface of it and the transformer architecture is as far as

80
00:08:38,640 --> 00:08:44,720
I know the answer. And I can't even say I can't even pretend that I really understand what the

81
00:08:44,720 --> 00:08:51,200
transformer architecture means in depth. But I have scanned it. And as I said I want to print it and

82
00:08:51,200 --> 00:08:57,760
really kind of think over it's at some point. And I'll probably feel bad about myself I think!

83
00:08:57,760 --> 00:09:03,280
Because weren't those guys in their in their 20s like? That's crazy! I think I asked ChatGPT

84
00:09:03,280 --> 00:09:09,439
once "who were the? Who wrote that paper and how old were they when it was published in Arxiv?"

85
00:09:09,439 --> 00:09:14,640
And I was expecting like, I don't know. What do you what do you imagine? I personally imagine kind of

86
00:09:14,640 --> 00:09:19,840
like you know you have these breakthroughs during COVID and things like that where like these kind

87
00:09:19,840 --> 00:09:24,480
of really obscure scientists who are like in their 50s and they've just kind of been laboring in

88
00:09:24,640 --> 00:09:31,120
labs and wearily writing and publishing in kind of obscure academic publications and they

89
00:09:31,120 --> 00:09:37,200
finally like hit a big or win a Nobel Prize. And then they're household household names. So I that

90
00:09:37,200 --> 00:09:42,680
was kind of what I had in mind. That was the mental image I'd formed of the birth of Arxiv.

91
00:09:42,680 --> 00:09:47,760
Like, I wasn't expecting 20-somethings in San Francisco! Though I thought that was both very very

92
00:09:47,760 --> 00:09:54,160
funny, very cool, and actually kind of inspiring. It's nice to think that people who you know just

93
00:09:54,160 --> 00:10:01,439
you might put them in the kind of milieu or bubble or world that you are in or credibly in through

94
00:10:01,439 --> 00:10:06,079
you know the series of connections that are coming up with such literally world changing

95
00:10:06,880 --> 00:10:13,439
innovations. So that was I thought anyway that that was cool. Okay voice training data. How

96
00:10:13,439 --> 00:10:19,280
are we doing? We're about 10 minutes. And I'm still talking about voice technology! So Whisper was

97
00:10:19,280 --> 00:10:25,680
brilliant. And I was so excited that I was my first instinct was to like guess it's like "oh my gosh

98
00:10:25,680 --> 00:10:31,040
I have to get like a really good microphone for this." So I didn't go on a spending spree because

99
00:10:31,040 --> 00:10:37,760
I said I'm gonna have to just wait a month and see if I still use this." And it just kind of became

100
00:10:37,760 --> 00:10:44,800
it's become really part of my daily routine. Like, if I'm writing an email I'll record a voice note

101
00:10:44,880 --> 00:10:50,079
and then I'll develop it and it's nice to see that everyone is like developing the same things in

102
00:10:50,079 --> 00:10:56,319
parallel. Like, that's maybe kind of a weird thing to say. But when I look, I kind of came when I started

103
00:10:56,319 --> 00:11:02,640
working on this these prototypes on GitHub, which is where I just kind of share very freely and loosely

104
00:11:03,199 --> 00:11:10,800
ideas and you know first iterations on concepts. And for want of a better word I called it like

105
00:11:11,439 --> 00:11:17,680
"LLM post processing." Or cleanup. Or basically a system prompt that after you get back the raw text

106
00:11:17,680 --> 00:11:25,920
from Whisper, you run it through model and say "okay this is crappy text like add sentence structure

107
00:11:25,920 --> 00:11:33,199
and you know fix it up. " And now when I'm exploring the different tools that are out there that people

108
00:11:33,200 --> 00:11:39,040
have built, I see quite a number of projects have basically you know done the same thing.

109
00:11:40,640 --> 00:11:45,040
Lest that be misconstrued, I'm not saying for a millisecond that I inspired them. I'm sure this

110
00:11:45,040 --> 00:11:51,440
has been a thing that's been integrated into tools for a while. But it's, it's the kind of thing that

111
00:11:51,440 --> 00:11:57,520
when you start using these tools every day the need for it is almost instantly apparent. Because text

112
00:11:57,600 --> 00:12:03,520
that doesn't have any punctuation or paragraph spacing takes a long time to you know, it takes so

113
00:12:03,520 --> 00:12:10,079
long to get it into a presentable email that,again, it moves speech tech into that,

114
00:12:11,280 --> 00:12:16,000
before that inflection point where you're like "nah it's just not worth." It it's like it'll just be

115
00:12:16,000 --> 00:12:20,800
quicker to type this. So it's it's a big - it's a little touch that actually is a big deal

116
00:12:21,520 --> 00:12:28,319
So I was on Whisper and I've been using Whisper and I kind of early on find a couple of tools.

117
00:12:28,319 --> 00:12:33,680
I couldn't find what I was looking for on Linux which is basically just something that'll run

118
00:12:34,800 --> 00:12:39,120
in the background. You'll give it an API key and it'll just like transcribe.

119
00:12:41,439 --> 00:12:47,359
With like a little key to start and stop the dictation. And the issues wer I discovered that

120
00:12:47,440 --> 00:12:52,720
like most people involved in creating these projects were very much focused on local models.

121
00:12:52,720 --> 00:12:58,400
And running Whisper locally because you can. And I tried that a bunch of times and just never

122
00:12:58,400 --> 00:13:03,920
got results that were as good as the cloud. And when I began looking at the cost of the speech to

123
00:13:03,920 --> 00:13:10,080
text APIs and what I was spending  just thought there it's actually in my opinion just one of

124
00:13:10,080 --> 00:13:15,600
the better deals in API spending and in cloud. Like, it's just not that expensive for very, very good

125
00:13:15,600 --> 00:13:22,240
models that are much more. You know, you're going to be able to run the full model, the latest model

126
00:13:22,240 --> 00:13:28,960
versus whatever you can run on your average GPU. Unless you want to buy a crazy GPU. It doesn't

127
00:13:28,960 --> 00:13:34,000
really make sense to me. Now, I privacy is another concern that I know is kind of like a very much

128
00:13:34,000 --> 00:13:38,720
a separate thing. That people just don't want their voice data and their voice leaving their

129
00:13:38,720 --> 00:13:45,360
local environment. Maybe for regulatory reasons as well. But I'm not in that. I'm don't really really

130
00:13:45,360 --> 00:13:51,440
care about people listening to my grocery list consisting of reminding myself that I need to buy

131
00:13:51,440 --> 00:13:58,240
more beer, Cheetos and hummus. Which is kind of the three three staples of my diet during periods of

132
00:13:58,240 --> 00:14:04,560
poor nutrition. But the kind of stuff that I transcribe most it's just not it's not a it's not a

133
00:14:04,560 --> 00:14:12,640
privacy thing. I'm not that sort of sensitive about. And I don't do anything so you know sensitive

134
00:14:12,640 --> 00:14:17,680
or secure that requires airgapping. So I looked at the pricing and especially the kind of older

135
00:14:17,680 --> 00:14:24,400
models mini. Some of them are very very affordable. And I did a back of the, I did a calculation once

136
00:14:24,400 --> 00:14:30,239
with ChatGPT and I was like "okay, this is the, this is the API price for I can't remember whatever

137
00:14:30,320 --> 00:14:37,040
the model was. Let's say I just go at it like nonstop which rarely happens. Probably I would say an

138
00:14:37,040 --> 00:14:45,200
average I might dictate 30 to 60 minutes per day if I was probably summing up the emails, documents,

139
00:14:45,200 --> 00:14:51,360
outlines. Which is a lot. But it's it's still a fairly modest amount. And I was like well some days I

140
00:14:51,360 --> 00:14:56,720
do go on like one or two days where I've been usually when I'm like kind of out of the house and

141
00:14:56,720 --> 00:15:02,800
just have something like I've nothing else to do. Like if I'm at a hospital. We have a newborn.

142
00:15:04,000 --> 00:15:09,040
And you're waiting for like hours and hours for an appointment. And I would probably have

143
00:15:09,040 --> 00:15:15,280
listened to podcasts before becoming a speech fanatic. And I'm like "oh wait let me just get down

144
00:15:15,280 --> 00:15:20,880
let me just get these ideas out of my head." And that's when I'll go on my speech binges. But those

145
00:15:20,880 --> 00:15:26,240
are like once every few months - like not frequently. But I said okay let's just say if I'm gonna price

146
00:15:26,240 --> 00:15:35,440
out cloud STT. If I was like dedicated every second of every waking hour to transcribing for some

147
00:15:35,440 --> 00:15:41,600
odd reason. I mean, I'd have to like eat and use the toilet! Like, you know there's only so many hours

148
00:15:41,600 --> 00:15:48,480
I'm awake for. So like let's just say a maximum of like 40 hour 45 minutes in the hours and I said

149
00:15:48,480 --> 00:15:55,360
all right let's just say 50. Who knows? You're dictating on the toilet! We do it! So you could just do 60.

150
00:15:55,440 --> 00:16:02,560
But whatever I did - and every day. Like you're going flat out, seven days a week dictating nonstop

151
00:16:02,560 --> 00:16:08,640
as like "what's my monthly API bill gonna be at this price?" And it came out to like 70 or

152
00:16:08,640 --> 00:16:14,960
80 bucks. And I was like, well that would be an extraordinary amount of dictation! And I would hope

153
00:16:15,600 --> 00:16:21,680
that there was some compelling reason more worth more than 70 dollars that I embarked upon that.

154
00:16:22,640 --> 00:16:26,959
So given that that's kind of the max point for me I said that's actually very very affordable.

155
00:16:27,920 --> 00:16:32,640
Now you're gonna if you want to spec out the costs and you want to do the post processing

156
00:16:33,599 --> 00:16:39,199
that I really do feel is valuable that's gonna cost more as well. Unless you're using

157
00:16:40,160 --> 00:16:47,839
Gemini which needless to say as a random person sitting in Jerusalem I have no affiliation nor with

158
00:16:47,840 --> 00:16:54,800
Google nor Anthropic nor Gemini nor any major tech vendor for that matter. Um I like Gemini

159
00:16:54,800 --> 00:17:00,080
not so much as a everyday model. Um it's kind of underwhelmed in that respect I would say.

160
00:17:00,080 --> 00:17:05,920
But for multimodal I think it's got a lot to offer. And I think that the transcribing functionality

161
00:17:05,920 --> 00:17:13,280
whereby it can um process audio with the system prompt and both give you a transcription that's

162
00:17:13,280 --> 00:17:20,079
cleaned up - that reduces two steps to one. And that for me is a very very big deal. And uh I feel like

163
00:17:20,079 --> 00:17:27,280
even Google hasn't really sort of thought through how useful the that modality is and what kind of

164
00:17:27,280 --> 00:17:33,280
use cases uh you can achieve with it. Because I found in the course of this year just an endless

165
00:17:33,280 --> 00:17:40,399
list of really kind of system prompt system prompt stuff that I can say "okay I've used it

166
00:17:40,560 --> 00:17:45,920
to capture context data for AI which is literally I might speak for if I wanted to have a good

167
00:17:45,920 --> 00:17:52,560
bank of context data about who knows my childhood uh more realistically maybe my career goals

168
00:17:53,520 --> 00:17:59,520
something that would just be like really boring to type out so I'll just like sit in my car

169
00:17:59,520 --> 00:18:06,640
and record it for 10 minutes. And that 10 minutes you get a lot of information in um emails which is

170
00:18:06,640 --> 00:18:13,200
short text uh just there is a whole bunch. And all these workflows kind of require a little bit

171
00:18:13,200 --> 00:18:18,320
of treatment afterwards and different treatment. My context pipeline is kind of like just extract the

172
00:18:18,320 --> 00:18:23,520
bare essential. So you end up with me talking very loosely about sort of what I've done in my career,

173
00:18:23,520 --> 00:18:30,000
where I've worked, where I might like to work. And it goes - it condenses that down to very robotic language

174
00:18:30,000 --> 00:18:36,000
that is easy to chunk, parse, and maybe put into a vector database. "Daniel has worked in technology!

175
00:18:36,080 --> 00:18:42,400
Daniel is a has been working in marketing." Stuff like that. That's not how you would speak um but I

176
00:18:42,400 --> 00:18:48,480
figure it's probably easier to parse for, after all, robots. So we've almost got to 20 minutes. And this

177
00:18:48,480 --> 00:18:56,880
is actually a success because I wasted 20 minutes of my uh of the evening speaking into microphone and

178
00:18:56,880 --> 00:19:02,720
the levels were shot and it uh it was clipping. And I said I can't really do an evaluation. I have to

179
00:19:02,720 --> 00:19:09,440
be fair. I have to give the models a chance to do their thing. Uh what am I hoping to achieve in this?

180
00:19:09,440 --> 00:19:14,960
Okay my fine tune was a dud as mentioned. Deepgram STT - I'm really really hopeful that this prototype

181
00:19:14,960 --> 00:19:20,560
will work. And it's a build in public open source. So anyone is welcome to use it if I make anything good

182
00:19:21,600 --> 00:19:28,000
But what was really exciting for me last night when after hours of um trying my own prototypes, seeing

183
00:19:28,080 --> 00:19:33,120
someone just made something that works like that. You know, you're not going to have to build a custom

184
00:19:34,240 --> 00:19:40,960
Conda environment and image. I have AMD GPU which makes things much more complicated. I didn't find it

185
00:19:41,840 --> 00:19:46,400
And I was about to give up and I said "all right. Let me just give Deepgram's Linux thing a shot

186
00:19:47,040 --> 00:19:50,960
and if this doesn't work um I'm just going to go back to trying to vibe code something myself."

187
00:19:51,600 --> 00:19:57,360
And when I ran the script - I was using Claude Code to do the installation process -

188
00:19:58,160 --> 00:20:02,800
it ran the script and "oh my gosh, it works!" Just like that! Uh the tricky thing

189
00:20:04,480 --> 00:20:12,480
for all those ones who want to know all the nitty gritty details um was that I don't think it was actually

190
00:20:12,480 --> 00:20:18,160
struggling with transcription but pasting. Wayland makes life very hard. And I think there was

191
00:20:18,160 --> 00:20:22,800
something not running at the right time. Anyway, Deepgram - I looked at how they actually handled

192
00:20:22,960 --> 00:20:28,960
that because it worked out of the box when other stuff didn't. And it was quite a clever little mechanism

193
00:20:29,520 --> 00:20:34,560
and but more so than that the accuracy was brilliant. Now, what am I doing here? This is going to be a 20

194
00:20:34,560 --> 00:20:44,399
minute audio uh sample and I'm I think I've done one or two of these before but I did it with

195
00:20:45,360 --> 00:20:51,120
short, snappy voice notes. This is kind of long form. This actually might be a better approximation

196
00:20:51,120 --> 00:20:55,040
for what's useful to me than voice memos like "I need to buy three

197
00:20:55,840 --> 00:20:59,840
liters of milk tomorrow and pita bread." Which is probably how like half my voice note

198
00:20:59,840 --> 00:21:04,399
voice notes sound. Like if anyone were to I don't know like find my phone they'd be like "this is

199
00:21:04,399 --> 00:21:09,280
the most boring person in the world!" Although actually there are some like kind of uh journaling

200
00:21:09,280 --> 00:21:14,080
thoughts as well. But it's a lot of content like that. And the probably for the evaluation the most

201
00:21:14,080 --> 00:21:22,560
useful thing is slightly obscure tech: Github, Nuclino, Hugging Face. Not so obscure that it's not

202
00:21:22,560 --> 00:21:27,360
going to have a chance of knowing it. But hopefully sufficiently well known that the models should get

203
00:21:27,360 --> 00:21:32,800
it. Uh I tried to do a little bit of speaking really fast and speaking very slowly. I would say in

204
00:21:32,800 --> 00:21:38,960
general I've spoken delivered this at a faster pace than I usually would owing to strong coffee

205
00:21:39,120 --> 00:21:44,240
flowing through my bloodstream. And the thing that I'm not going to get in this benchmark is

206
00:21:44,240 --> 00:21:49,920
background noise. Which in my first take that I had to get rid of my wife came in with my son

207
00:21:49,920 --> 00:21:55,680
for a good night kiss. And that actually would have been super helpful to get in because it was

208
00:21:56,400 --> 00:22:01,600
non-diarised. Or if we had diarisation a female I could say I want the male voice and that

209
00:22:01,600 --> 00:22:06,240
wasn't intended for transcription um. And we're not going to get background noise like people

210
00:22:06,240 --> 00:22:11,840
honking their horns. Which is something I've done in my main dataset where I am trying to go back

211
00:22:11,840 --> 00:22:16,880
to some of my voice notes, annotate them, and run a benchmark. But this is going to be just a pure

212
00:22:17,680 --> 00:22:24,960
quick test. And as someone I'm working on a voice note idea that's my sort of end

213
00:22:26,560 --> 00:22:30,320
motivation besides thinking it's an absolute outstanding technology that's coming to

214
00:22:30,960 --> 00:22:36,240
viability and really - I know this sounds cheesy - can actually have a very transformative effect.

215
00:22:37,120 --> 00:22:42,720
It's, you know, voice technology has been life changing for folks living with

216
00:22:44,000 --> 00:22:49,760
disabilities. And I think there's something really nice about the fact that it can also benefit

217
00:22:50,480 --> 00:22:54,639
you know folks who are able-bodied. And like we can all in different ways

218
00:22:55,120 --> 00:23:02,560
um make this tech as useful as possible regardless of the exact way that we're using it um. And I

219
00:23:02,560 --> 00:23:07,760
think there's something very powerful in that. And it can be very cool um I see huge potential. What

220
00:23:07,760 --> 00:23:14,480
excites me about voice tech - a lot of things actually. Firstly the fact that it's cheap and accurate

221
00:23:14,480 --> 00:23:19,040
as I mentioned at the very start of this um. And it's getting better and better with stuff like

222
00:23:19,040 --> 00:23:24,160
accent handling um. I'm not sure my my fine tune will actually ever come to fruition in the

223
00:23:24,160 --> 00:23:30,240
sense that I'll use it day to day as I imagine and get like superb flawless words error rates. Because

224
00:23:30,240 --> 00:23:37,680
I'm just kind of skeptical about local speech to tech as I mentioned. And I think the pace of

225
00:23:37,680 --> 00:23:42,720
innovation and improvement in the models. The main reasons for fine tuning from what I've seen

226
00:23:44,320 --> 00:23:50,480
have been people who are something that really blows blows my mind about ASR is the idea that it's

227
00:23:50,480 --> 00:24:00,080
inherently a-llingual. Or multilingual. Phonetic-based. So as folks who use speak very obscure languages

228
00:24:00,080 --> 00:24:04,800
that there may be there there might be a paucity of training data or almost none at all. And therefore

229
00:24:04,800 --> 00:24:11,440
the accuracy is significantly reduced. Or folks in very critical environments. I know there are

230
00:24:11,440 --> 00:24:17,680
this is used extensively in medical transcription and dispatcher work as um you know the call

231
00:24:17,680 --> 00:24:24,000
centers who send out ambulances etc where accuracy is absolutely paramount. And in the case of doctors,

232
00:24:24,560 --> 00:24:29,680
radiologists they might be using very specialized vocab all the time. So those are kind of the main

233
00:24:29,680 --> 00:24:35,680
two things. And I'm not sure that really just for trying to make it better on a few random tech words

234
00:24:35,680 --> 00:24:41,840
with my slightly. I mean, I have an accent!  But like, not you know an accent that a few other million

235
00:24:41,840 --> 00:24:50,720
people have. Ish. I'm not sure that my little fine tune is going to actually like the bump in

236
00:24:50,720 --> 00:24:55,760
word error reduction if I ever actually figure out how to do it and get it up to the cloud. By the

237
00:24:55,760 --> 00:25:00,879
time we've done that I suspect that the next generation of ASR will just be so good that it will

238
00:25:00,879 --> 00:25:07,040
kind of be "nah, well, that would be cool if it worked out. But I'll just use this instead." So that's going to be

239
00:25:07,280 --> 00:25:15,040
it for today's episodes of voice training data single long shot evaluation. Who am I going to

240
00:25:15,040 --> 00:25:21,200
compare? Whisper is always good as a benchmark. But I'm more interested in seeing Whisper head-to-head

241
00:25:21,200 --> 00:25:27,680
with two things really. One is Whisper variants. So you've got these projects like Faster Whisper,

242
00:25:29,120 --> 00:25:34,000
Distilled Whisper. It's a bit confusing. There's a whole bunch of them. And the emerging ASRs which

243
00:25:34,160 --> 00:25:38,960
are also a thing. My intention for this is I'm not sure I'm going to have the time in any point

244
00:25:38,960 --> 00:25:46,320
of the foreseeable future to go back through this whole episode and create a proper source truth or I fix

245
00:25:47,520 --> 00:25:53,760
everything. I might do it if I can get one transcription that's sufficiently close to perfection.

246
00:25:54,960 --> 00:26:00,560
But what I would actually love to do on Hugging Face I think would be a great probably how I might

247
00:26:00,560 --> 00:26:08,080
visualize this is having the audio waveform play. And then have the transcript for each model below

248
00:26:08,080 --> 00:26:16,320
it. And maybe even a like you know to scale. And maybe even a local one as well like local Whisper

249
00:26:16,320 --> 00:26:23,919
versus Open AI API etc. And I can then actually listen back to segments. Or anyone who wants to

250
00:26:24,000 --> 00:26:30,000
can listen back to segments of this recording and see where a particular model struggled

251
00:26:30,000 --> 00:26:35,600
while others didn't, as well as the sort of headline finding of which had the best WER. But that would

252
00:26:35,600 --> 00:26:41,120
require the source of truth. Okay, that's it. Hope this was, I don't know, maybe useful for other

253
00:26:41,120 --> 00:26:46,480
folks interested in STT. You want to see - that I always feel think I've just said as something I

254
00:26:46,480 --> 00:26:52,800
didn't intend to. STT I said for those listening carefully! Including hopefully the models themselves!

255
00:26:53,280 --> 00:26:58,960
This has been myself Daniel Rosehill. For more um jumbled repositories about my uh roving interests

256
00:26:58,960 --> 00:27:06,639
in AI. But particularly agentic AI, MCP, and voice tech, you can find me on Github, Hugging Face.

257
00:27:08,080 --> 00:27:14,000
Where else? DanielRosehilll.com which is my personal website. As well as this podcast whose name

258
00:27:14,000 --> 00:27:17,280
I sadly cannot remember! Until next time, thanks for listening!

